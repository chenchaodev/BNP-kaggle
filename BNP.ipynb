{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input', 'lr_dispression_sfm.csv', 'lr_dispression_sfm_0.25.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if (os.path.isdir('D:\\\\Documents\\\\DMProject\\\\BNP\\\\')):\n",
    "    os.chdir('D:\\\\Documents\\\\DMProject\\\\BNP\\\\')\n",
    "if (os.path.isdir('C:\\\\Users\\\\Chao\\\\Documents\\\\DMProject\\\\BNP\\\\')):\n",
    "    os.chdir('C:\\\\Users\\\\Chao\\\\Documents\\\\DMProject\\\\BNP\\\\')\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input\\\\train.csv')\n",
    "test = pd.read_csv('input\\\\test.csv')\n",
    "target = train['target']\n",
    "id_test = test['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop(['ID', 'target'], axis=1)\n",
    "test = test.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v3\n",
       "A       227\n",
       "B        53\n",
       "C    110584\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = train.groupby('v3')\n",
    "g.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18210"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = train.groupby('v22')\n",
    "len(g.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string_column_names = ['v3', 'v22', 'v24', 'v30', 'v31', \n",
    "                    'v47', 'v52', 'v56', 'v66', 'v71', \n",
    "                    'v74', 'v75', 'v79', 'v91', \n",
    "                    'v107', 'v110', 'v112', 'v113', 'v125']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3\n",
      "3\n",
      "v22\n",
      "18210\n",
      "v24\n",
      "5\n",
      "v30\n",
      "7\n",
      "v31\n",
      "3\n",
      "v47\n",
      "10\n",
      "v52\n",
      "12\n",
      "v56\n",
      "122\n",
      "v66\n",
      "3\n",
      "v71\n",
      "9\n",
      "v72\n",
      "13\n",
      "v74\n",
      "3\n",
      "v75\n",
      "4\n",
      "v79\n",
      "18\n",
      "v91\n",
      "7\n",
      "v107\n",
      "7\n",
      "v110\n",
      "3\n",
      "v112\n",
      "22\n",
      "v113\n",
      "36\n",
      "v125\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for column_name in string_column_names:\n",
    "    print(column_name)\n",
    "    g = train.groupby(column_name)\n",
    "    print(len(g.size()))\n",
    "#     print(g.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v125\n",
       "BZ       3\n",
       "AX      13\n",
       "BB      68\n",
       "AJ      82\n",
       "AB     189\n",
       "F      221\n",
       "BS     240\n",
       "O      248\n",
       "I      253\n",
       "AH     343\n",
       "BA     349\n",
       "BG     355\n",
       "BC     394\n",
       "CI     397\n",
       "BT     407\n",
       "AS     427\n",
       "AM     444\n",
       "CL     461\n",
       "AQ     469\n",
       "AD     486\n",
       "BP     504\n",
       "BF     511\n",
       "C      514\n",
       "AV     538\n",
       "AA     542\n",
       "T      615\n",
       "CK     623\n",
       "M      636\n",
       "BR     642\n",
       "AO     644\n",
       "      ... \n",
       "BL    1214\n",
       "R     1217\n",
       "BX    1297\n",
       "BU    1369\n",
       "CJ    1446\n",
       "P     1463\n",
       "BK    1477\n",
       "CA    1523\n",
       "A     1528\n",
       "AN    1539\n",
       "Z     1595\n",
       "AC    1945\n",
       "CD    2059\n",
       "AR    2229\n",
       "B     2374\n",
       "AZ    2416\n",
       "BD    2452\n",
       "BW    2478\n",
       "L     2502\n",
       "E     2521\n",
       "G     2594\n",
       "K     2835\n",
       "H     3212\n",
       "V     3234\n",
       "BY    3311\n",
       "AP    3410\n",
       "CG    3826\n",
       "BJ    4465\n",
       "AK    5337\n",
       "BM    5759\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = train.groupby('v125')\n",
    "len(g.size())\n",
    "g.size().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "future = train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop(['v3', 'v22', 'v24', 'v30', 'v31', \n",
    "                    'v47', 'v52', 'v56', 'v66', 'v71', \n",
    "                    'v72', 'v74', 'v75', 'v79', 'v91', \n",
    "                    'v107', 'v110', 'v112', 'v113', 'v125'], axis=1)\n",
    "test = test.drop(['v3', 'v22', 'v24', 'v30', 'v31', \n",
    "                    'v47', 'v52', 'v56', 'v66', 'v71', \n",
    "                    'v72', 'v74', 'v75', 'v79', 'v91', \n",
    "                    'v107', 'v110', 'v112', 'v113', 'v125'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['v1', 'v2', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12',\n",
       "       'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21',\n",
       "       'v23', 'v25', 'v26', 'v27', 'v28', 'v29', 'v32', 'v33', 'v34',\n",
       "       'v35', 'v36', 'v37', 'v38', 'v39', 'v40', 'v41', 'v42', 'v43',\n",
       "       'v44', 'v45', 'v46', 'v48', 'v49', 'v50', 'v51', 'v53', 'v54',\n",
       "       'v55', 'v57', 'v58', 'v59', 'v60', 'v61', 'v62', 'v63', 'v64',\n",
       "       'v65', 'v67', 'v68', 'v69', 'v70', 'v73', 'v76', 'v77', 'v78',\n",
       "       'v80', 'v81', 'v82', 'v83', 'v84', 'v85', 'v86', 'v87', 'v88',\n",
       "       'v89', 'v90', 'v92', 'v93', 'v94', 'v95', 'v96', 'v97', 'v98',\n",
       "       'v99', 'v100', 'v101', 'v102', 'v103', 'v104', 'v105', 'v106',\n",
       "       'v108', 'v109', 'v111', 'v114', 'v115', 'v116', 'v117', 'v118',\n",
       "       'v119', 'v120', 'v121', 'v122', 'v123', 'v124', 'v126', 'v127',\n",
       "       'v128', 'v129', 'v130', 'v131'], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# futrue = future - ['v3', 'v22', 'v24', 'v107', 'v110', 'v112', 'v113', 'v125']\n",
    "future = train.columns.values\n",
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# future = future[1:]\n",
    "# future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "print('Load data...')\n",
    "train = pd.read_csv(\"C:\\\\Users\\\\Chao\\\\Documents\\\\DMProject\\\\BNP\\\\input\\\\train.csv\")\n",
    "target = train['target'].values\n",
    "train = train.drop(['ID','target',\n",
    "                    'v8','v23','v25','v36','v37',\n",
    "                    'v46','v51','v53','v54','v63',\n",
    "                    'v73','v75','v79','v81','v82',\n",
    "                    'v89','v92','v95','v105','v107',\n",
    "                    'v108','v109','v110','v116','v117',\n",
    "                    'v118','v119','v123','v124','v128'],axis=1)\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\Chao\\\\Documents\\\\DMProject\\\\BNP\\\\input\\\\test.csv\")\n",
    "id_test = test['ID'].values\n",
    "test = test.drop(['ID','v8','v23','v25','v36','v37',\n",
    "                  'v46','v51','v53','v54','v63','v73',\n",
    "                  'v75','v79','v81','v82','v89','v92',\n",
    "                  'v95','v105','v107','v108','v109',\n",
    "                  'v110','v116','v117','v118','v119',\n",
    "                  'v123','v124','v128'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Clearing...')\n",
    "for (train_name, train_series), (test_name, test_series) in zip(train.iteritems(),test.iteritems()):\n",
    "    if train_series.dtype == 'O':\n",
    "        #for objects: factorize\n",
    "        train[train_name], tmp_indexer = pd.factorize(train[train_name])\n",
    "        test[test_name] = tmp_indexer.get_indexer(test[test_name])\n",
    "        #but now we have -1 values (NaN)\n",
    "    else:\n",
    "        #for int or float: fill NaN\n",
    "        tmp_len = len(train[train_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            #print \"mean\", train_series.mean()\n",
    "            train.loc[train_series.isnull(), train_name] = -999 \n",
    "        #and Test\n",
    "        tmp_len = len(test[test_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            test.loc[test_series.isnull(), test_name] = -999\n",
    "\n",
    "X_train = train\n",
    "X_test = test\n",
    "print('Training...')\n",
    "extc = ExtraTreesClassifier(n_estimators=850,max_features= 60,criterion= 'entropy',min_samples_split= 4,\n",
    "                            max_depth= 40, min_samples_leaf= 2, n_jobs = -1)    \n",
    "\n",
    "extc.fit(X_train,target) \n",
    "\n",
    "print('Predict...')\n",
    "y_pred = extc.predict_proba(X_test)\n",
    "#print y_pred\n",
    "\n",
    "pd.DataFrame({\"ID\": id_test, \"PredictedProb\": y_pred[:,1]}).to_csv('extra_trees.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #在scikit的特定情形下，用joblib’s来代替pickle（joblib.dump&joblib.load）会更吸引人，在大数据下效率更高，但只能pickle到磁盘而不是字符串：\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(extc, 'C:\\\\Users\\\\Chao\\\\Documents\\\\DMProject\\\\BNP\\\\BNP_tree.pkl') \n",
    "\n",
    "# # doctest: +SKIP\n",
    "\n",
    "# #你可以在之后重新加载pickled模型（可以在另一个Python程序里）：\n",
    "\n",
    "# #clf = joblib.load('filename.pkl') # doctest:+SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 114393)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_imputed = imp.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_imputed = imp.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg    = LogisticRegression(random_state=1)\n",
    "alg.fit(train_imputed, target)\n",
    "# scores = cross_validation.cross_val_score(\n",
    "#     alg,\n",
    "#     train_imputed[future],\n",
    "#     target,\n",
    "#     cv=3.\n",
    "# )\n",
    "\n",
    "# print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114393"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = alg.predict_proba(test_imputed)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_value = alg.predict(test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114393"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print y_pred\n",
    "\n",
    "pd.DataFrame({\"ID\": id_test, \"PredictedProb\": y_pred[:,1]}).to_csv('lr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
