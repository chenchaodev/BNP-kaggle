{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scikit learn ensembe workflow for binary probability\n",
    "import time; start_time = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random; random.seed(2016)\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "num_train = train.shape[0]\n",
    "\n",
    "y_train = train['target']\n",
    "train = train.drop(['target'],axis=1)\n",
    "id_test = test['ID']\n",
    "\n",
    "def fill_nan_null(val):\n",
    "    ret_fill_nan_null = 0.0\n",
    "    if val == True:\n",
    "        ret_fill_nan_null = 1.0\n",
    "    return ret_fill_nan_null\n",
    "\n",
    "df_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "df_all['null_count'] = df_all.isnull().sum(axis=1).tolist()\n",
    "df_all_temp = df_all['ID']\n",
    "df_all = df_all.drop(['ID'],axis=1)\n",
    "df_data_types = df_all.dtypes[:] #{'object':0,'int64':0,'float64':0,'datetime64':0}\n",
    "d_col_drops = []\n",
    "\n",
    "for i in range(len(df_data_types)):\n",
    "    df_all[str(df_data_types.index[i])+'_nan_'] = df_all[str(df_data_types.index[i])].map(lambda x:fill_nan_null(pd.isnull(x)))\n",
    "df_all = df_all.fillna(-9999)\n",
    "#df_all = df_all.replace(0, -9999)\n",
    "\n",
    "for i in range(len(df_data_types)):\n",
    "    if str(df_data_types[i])=='object':\n",
    "        df_u = pd.unique(df_all[str(df_data_types.index[i])].ravel())\n",
    "        print(\"Column: \", str(df_data_types.index[i]), \" Length: \", len(df_u))\n",
    "        d={}\n",
    "        j = 1000\n",
    "        for s in df_u:\n",
    "            d[str(s)]=j\n",
    "            j+=5\n",
    "        df_all[str(df_data_types.index[i])+'_vect_'] = df_all[str(df_data_types.index[i])].map(lambda x:d[str(x)])\n",
    "        d_col_drops.append(str(df_data_types.index[i]))\n",
    "        if len(df_u)<150:\n",
    "            dummies = pd.get_dummies(df_all[str(df_data_types.index[i])]).rename(columns=lambda x: str(df_data_types.index[i]) + '_' + str(x))\n",
    "            df_all_temp = pd.concat([df_all_temp, dummies], axis=1)\n",
    "\n",
    "df_all_temp = df_all_temp.drop(['ID'],axis=1)\n",
    "df_all = pd.concat([df_all, df_all_temp], axis=1)\n",
    "print(len(df_all), len(df_all.columns))\n",
    "#df_all.to_csv(\"df_all.csv\")\n",
    "train = df_all.iloc[:num_train]\n",
    "test = df_all.iloc[num_train:]\n",
    "train = train.drop(d_col_drops,axis=1)\n",
    "test = test.drop(d_col_drops,axis=1)\n",
    "\n",
    "def flog_loss(ground_truth, predictions):\n",
    "    flog_loss_ = log_loss(ground_truth, predictions) #, eps=1e-15, normalize=True, sample_weight=None)\n",
    "    return flog_loss_\n",
    "LL  = make_scorer(flog_loss, greater_is_better=False)\n",
    "\n",
    "g={'ne':150,'md':6,'mf':80,'rs':2016} #change to g={'ne':500,'md':40,'mf':60,'rs':2016}\n",
    "etc = ensemble.ExtraTreesClassifier(n_estimators=g['ne'], max_depth=g['md'], max_features=g['mf'], random_state=g['rs'], criterion='entropy', min_samples_split= 4, min_samples_leaf= 2, verbose = 0, n_jobs =-1)      \n",
    "etr = ensemble.ExtraTreesRegressor(n_estimators=g['ne'], max_depth=g['md'], max_features=g['mf'], random_state=g['rs'], min_samples_split= 4, min_samples_leaf= 2, verbose = 0, n_jobs =-1)      \n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=g['ne'], max_depth=g['md'], max_features=g['mf'], random_state=g['rs'], criterion='entropy', min_samples_split= 4, min_samples_leaf= 2, verbose = 0, n_jobs =-1)\n",
    "rfr = ensemble.RandomForestRegressor(n_estimators=g['ne'], max_depth=g['md'], max_features=g['mf'], random_state=g['rs'], min_samples_split= 4, min_samples_leaf= 2, verbose = 0, n_jobs =-1)\n",
    "xgr = xgb.XGBRegressor(n_estimators=g['ne'], max_depth=g['md'], seed=g['rs'], missing=np.nan, learning_rate=0.02, subsample=0.9, colsample_bytree=0.85, objective='reg:linear')\n",
    "xgc = xgb.XGBClassifier(n_estimators=g['ne'], max_depth=g['md'], seed=g['rs'], missing=np.nan, learning_rate=0.02, subsample=0.9, colsample_bytree=0.85, objective='binary:logistic') #try 'binary:logitraw'\n",
    "#clf = {'etc':etc, 'etr':etr, 'rfc':rfc, 'rfr':rfr, 'xgr':xgr, 'xgc':xgc} # use this line instead\n",
    "clf = {'etr':etr, 'rfr':rfr, 'xgr':xgr} # removed due to kaggle performance, would prefer less time and more cores than more time and less cores :)\n",
    "\n",
    "y_pred=[]\n",
    "best_score = 0.0\n",
    "id_results = id_test[:]\n",
    "for c in clf:\n",
    "    if c[:1] != \"x\": #not xgb\n",
    "        model = GridSearchCV(estimator=clf[c], param_grid={}, n_jobs =-1, cv=2, verbose=0, scoring=LL)\n",
    "        model.fit(train, y_train.values)\n",
    "        if c[-1:] != \"c\": #not classifier\n",
    "            y_pred = model.predict(test)\n",
    "            print(\"Ensemble Model: \", c, \" Best CV score: \", model.best_score_, \" Time: \", round(((time.time() - start_time)/60),2))\n",
    "        else: #classifier\n",
    "            best_score = (log_loss(y_train.values, model.predict_proba(train)))*-1\n",
    "            y_pred = model.predict_proba(test)[:,1]\n",
    "            print(\"Ensemble Model: \", c, \" Best CV score: \", best_score, \" Time: \", round(((time.time() - start_time)/60),2))\n",
    "    else: #xgb\n",
    "        X_fit, X_eval, y_fit, y_eval= train_test_split(train, y_train, test_size=0.35, train_size=0.65, random_state=g['rs'])\n",
    "        model = clf[c]\n",
    "        model.fit(X_fit, y_fit.values, early_stopping_rounds=20, eval_metric=\"logloss\", eval_set=[(X_eval, y_eval)], verbose=0)\n",
    "        if c == \"xgr\": #xgb regressor\n",
    "            best_score = (log_loss(y_train.values, model.predict(train)))*-1\n",
    "            y_pred = model.predict(test)\n",
    "        else: #xgb classifier\n",
    "            best_score = (log_loss(y_train.values, model.predict_proba(train)))*-1\n",
    "            y_pred = model.predict_proba(test)[:,1]\n",
    "        print(\"Ensemble Model: \", c, \" Best CV score: \", best_score, \" Time: \", round(((time.time() - start_time)/60),2))\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i]<0.0:\n",
    "            y_pred[i] = 0.0\n",
    "        if y_pred[i]>1.0:\n",
    "            y_pred[i] = 1.0\n",
    "    df_in = pd.DataFrame({\"ID\": id_test, c: y_pred})\n",
    "    id_results = pd.concat([id_results, df_in[c]], axis=1)\n",
    "id_results['avg'] = id_results.drop('ID', axis=1).apply(np.average, axis=1)\n",
    "id_results['min'] = id_results.drop('ID', axis=1).apply(min, axis=1)\n",
    "id_results['max'] = id_results.drop('ID', axis=1).apply(max, axis=1)\n",
    "id_results['diff'] = id_results['max'] - id_results['min']\n",
    "for i in range(10):\n",
    "    print(i, len(id_results[id_results['diff']>(i/10)]))\n",
    "id_results.to_csv(\"results_analysis.csv\", index=False)\n",
    "ds = id_results[['ID','avg']]\n",
    "ds.columns = ['ID','PredictedProb']\n",
    "ds.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
